{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/digit-recognizer/sample_submission.csv\n/kaggle/input/digit-recognizer/train.csv\n/kaggle/input/digit-recognizer/test.csv\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cloud AutoML\nPROJECT_ID = 'automl-exercise-307804'\nfrom google.cloud import automl_v1beta1 as automl\nautoml_client = automl.AutoMlClient()","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense , Dropout , Lambda, Flatten\nfrom keras.optimizers import Adam ,RMSprop\nfrom sklearn.model_selection import train_test_split\nfrom keras import  backend as K\nfrom keras.preprocessing.image import ImageDataGenerator","execution_count":8,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/digit-recognizer/train.csv\")\nprint(train.shape)\ntrain.head()","execution_count":2,"outputs":[{"output_type":"stream","text":"(42000, 785)\n","name":"stdout"},{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n0      1       0       0       0       0       0       0       0       0   \n1      0       0       0       0       0       0       0       0       0   \n2      1       0       0       0       0       0       0       0       0   \n3      4       0       0       0       0       0       0       0       0   \n4      0       0       0       0       0       0       0       0       0   \n\n   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n0       0  ...         0         0         0         0         0         0   \n1       0  ...         0         0         0         0         0         0   \n2       0  ...         0         0         0         0         0         0   \n3       0  ...         0         0         0         0         0         0   \n4       0  ...         0         0         0         0         0         0   \n\n   pixel780  pixel781  pixel782  pixel783  \n0         0         0         0         0  \n1         0         0         0         0  \n2         0         0         0         0  \n3         0         0         0         0  \n4         0         0         0         0  \n\n[5 rows x 785 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>pixel0</th>\n      <th>pixel1</th>\n      <th>pixel2</th>\n      <th>pixel3</th>\n      <th>pixel4</th>\n      <th>pixel5</th>\n      <th>pixel6</th>\n      <th>pixel7</th>\n      <th>pixel8</th>\n      <th>...</th>\n      <th>pixel774</th>\n      <th>pixel775</th>\n      <th>pixel776</th>\n      <th>pixel777</th>\n      <th>pixel778</th>\n      <th>pixel779</th>\n      <th>pixel780</th>\n      <th>pixel781</th>\n      <th>pixel782</th>\n      <th>pixel783</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 785 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv(\"/kaggle/input/digit-recognizer/test.csv\")\nprint(test.shape)\ntest.head()","execution_count":3,"outputs":[{"output_type":"stream","text":"(28000, 784)\n","name":"stdout"},{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n0       0       0       0       0       0       0       0       0       0   \n1       0       0       0       0       0       0       0       0       0   \n2       0       0       0       0       0       0       0       0       0   \n3       0       0       0       0       0       0       0       0       0   \n4       0       0       0       0       0       0       0       0       0   \n\n   pixel9  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n0       0  ...         0         0         0         0         0         0   \n1       0  ...         0         0         0         0         0         0   \n2       0  ...         0         0         0         0         0         0   \n3       0  ...         0         0         0         0         0         0   \n4       0  ...         0         0         0         0         0         0   \n\n   pixel780  pixel781  pixel782  pixel783  \n0         0         0         0         0  \n1         0         0         0         0  \n2         0         0         0         0  \n3         0         0         0         0  \n4         0         0         0         0  \n\n[5 rows x 784 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pixel0</th>\n      <th>pixel1</th>\n      <th>pixel2</th>\n      <th>pixel3</th>\n      <th>pixel4</th>\n      <th>pixel5</th>\n      <th>pixel6</th>\n      <th>pixel7</th>\n      <th>pixel8</th>\n      <th>pixel9</th>\n      <th>...</th>\n      <th>pixel774</th>\n      <th>pixel775</th>\n      <th>pixel776</th>\n      <th>pixel777</th>\n      <th>pixel778</th>\n      <th>pixel779</th>\n      <th>pixel780</th>\n      <th>pixel781</th>\n      <th>pixel782</th>\n      <th>pixel783</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 784 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = (train.iloc[:,1:].values).astype('float32') # all pixel values\ny_train = train.iloc[:,0].values.astype('int32') # only labels i.e targets digits\nX_test = test.values.astype('float32')","execution_count":4,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Visualization and Scaling"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Convert train datset to (num_images, img_rows, img_cols) format \nX_train = X_train.reshape(X_train.shape[0], 28, 28)\n\nfor i in range(6,8):\n    plt.subplot(330 + (i+1))\n    plt.imshow(X_train[i], cmap=plt.get_cmap('gray'))\n    plt.title(y_train[i])","execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 2 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#expand 1 more dimention as 1 for colour channel gray\nX_train = X_train.reshape(X_train.shape[0], 28, 28,1)\nX_test = X_test.reshape(X_test.shape[0], 28, 28,1)\n\nX_train.shape, X_test.shape","execution_count":19,"outputs":[{"output_type":"execute_result","execution_count":19,"data":{"text/plain":"((42000, 28, 28, 1), (28000, 28, 28, 1))"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature standardization for better performance\nmean_px = X_train.mean().astype(np.float32)\nstd_px = X_train.std().astype(np.float32)\n\ndef standardize(x): \n    return (x-mean_px)/std_px\n","execution_count":21,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# One hot encoding of labels\nfrom keras.utils.np_utils import to_categorical\ny_train= to_categorical(y_train)\nnum_classes = y_train.shape[1]\nnum_classes","execution_count":22,"outputs":[{"output_type":"execute_result","execution_count":22,"data":{"text/plain":"10"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## Neural Network Architecture"},{"metadata":{"trusted":true},"cell_type":"code","source":"# fix random seed for reproducibility\nseed = 43\nnp.random.seed(seed)","execution_count":23,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import  Sequential\nfrom keras.layers.core import  Lambda , Dense, Flatten, Dropout\nfrom keras.callbacks import EarlyStopping\nfrom keras.layers import BatchNormalization, Convolution2D , MaxPooling2D","execution_count":24,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Linear model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model with \n# lambda layer (perform arithmetic (sum, avg, exp)), \n# Flatten (to transform to 1D array)\n# Dense (all connected nodes) - 10 nodes to represent each digit (attach softmax to reduce range to 0 to 1)\n\nmodel= Sequential()\nmodel._name = 'Linear'\nmodel.add(Lambda(standardize,input_shape=(28,28,1)))\nmodel.add(Flatten())\nmodel.add(Dense(10, activation='softmax'))\nprint(\"input shape \",model.input_shape)\nprint(\"output shape \",model.output_shape)","execution_count":25,"outputs":[{"output_type":"stream","text":"input shape  (None, 28, 28, 1)\noutput shape  (None, 10)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compile network \n# Defining loss function, optimzer and metrics\n\nfrom keras.optimizers import RMSprop\nmodel.compile(optimizer=RMSprop(lr=0.001), loss='categorical_crossentropy', \n              metrics=['accuracy'])\n\nfrom keras.preprocessing import image\ngen = image.ImageDataGenerator()","execution_count":27,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cross Validation\nfrom sklearn.model_selection import train_test_split\nX = X_train\ny = y_train\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.10, random_state=42)\nbatches = gen.flow(X_train, y_train, batch_size=64)\nval_batches = gen.flow(X_val, y_val, batch_size=64)","execution_count":28,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nhistory = model.fit_generator(generator=batches, steps_per_epoch=batches.n, epochs=3, \n                    validation_data=val_batches, validation_steps=val_batches.n)","execution_count":37,"outputs":[{"output_type":"stream","text":"Epoch 1/3\n   40/34020 [..............................] - ETA: 1:31 - loss: 0.3089 - accuracy: 0.9141","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n  warnings.warn('`Model.fit_generator` is deprecated and '\n","name":"stderr"},{"output_type":"stream","text":"34020/34020 [==============================] - 2s 49us/step - loss: 0.3061 - accuracy: 0.9118 - val_loss: 0.2897 - val_accuracy: 0.9159\nCPU times: user 2.31 s, sys: 275 ms, total: 2.59 s\nWall time: 1.72 s\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":33,"outputs":[{"output_type":"stream","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nlambda (Lambda)              (None, 28, 28, 1)         0         \n_________________________________________________________________\nflatten (Flatten)            (None, 784)               0         \n_________________________________________________________________\ndense (Dense)                (None, 10)                7850      \n=================================================================\nTotal params: 7,850\nTrainable params: 7,850\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#predictions\npredictions = model.predict_classes(X_test, verbose=0)\nsubmissions=pd.DataFrame({\"ImageId\": list(range(1,len(predictions)+1)),\n                         \"Label\": predictions})\nsubmissions.to_csv(\"Linear.csv\", index=False, header=True)","execution_count":36,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Fully Connected Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_fc_model():\n    model = Sequential([\n        Lambda(standardize, input_shape=(28,28,1)),\n        Flatten(),\n        Dense(512, activation='relu'),\n        Dense(10, activation='softmax')\n        ])\n    model._name = 'Fully_Connected'\n    model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n    return model","execution_count":38,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fc = get_fc_model()\nfc.optimizer.lr=0.01\nhistory = fc.fit_generator(generator=batches, steps_per_epoch=batches.n, epochs=1, \n                    validation_data=val_batches, validation_steps=val_batches.n)","execution_count":39,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fc.summary()","execution_count":41,"outputs":[{"output_type":"stream","text":"Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nlambda_1 (Lambda)            (None, 28, 28, 1)         0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 784)               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 512)               401920    \n_________________________________________________________________\ndense_2 (Dense)              (None, 10)                5130      \n=================================================================\nTotal params: 407,050\nTrainable params: 407,050\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#predictions\npredictions = fc.predict_classes(X_test, verbose=0)\nsubmissions=pd.DataFrame({\"ImageId\": list(range(1,len(predictions)+1)),\n                         \"Label\": predictions})\nsubmissions.to_csv(\"FC.csv\", index=False, header=True)","execution_count":42,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Convolutional Neural Network"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers import Convolution2D, MaxPooling2D\n\ndef get_cnn_model():\n    model = Sequential([\n        Lambda(standardize, input_shape=(28,28,1)),\n        Convolution2D(32,(3,3), activation='relu'),\n        Convolution2D(32,(3,3), activation='relu'),\n        MaxPooling2D(),\n        Convolution2D(64,(3,3), activation='relu'),\n        Convolution2D(64,(3,3), activation='relu'),\n        MaxPooling2D(),\n        Flatten(),\n        Dense(512, activation='relu'),\n        Dense(10, activation='softmax')\n        ])\n    model.compile(Adam(), loss='categorical_crossentropy',\n                  metrics=['accuracy'])\n    model._name = 'CNN'\n    return model","execution_count":51,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cnn_model= get_cnn_model()\ncnn_model.optimizer.lr=0.01\nhistory = cnn_model.fit_generator(generator=batches, steps_per_epoch=batches.n, epochs=1, \n                              validation_data=val_batches, validation_steps=val_batches.n)","execution_count":52,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n  warnings.warn('`Model.fit_generator` is deprecated and '\n","name":"stderr"},{"output_type":"stream","text":"34020/34020 [==============================] - 3s 81us/step - loss: 0.2569 - accuracy: 0.9209 - val_loss: 0.1600 - val_accuracy: 0.9556\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"cnn_model.summary()","execution_count":54,"outputs":[{"output_type":"stream","text":"Model: \"CNN\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nlambda_5 (Lambda)            (None, 28, 28, 1)         0         \n_________________________________________________________________\nconv2d_12 (Conv2D)           (None, 26, 26, 32)        320       \n_________________________________________________________________\nconv2d_13 (Conv2D)           (None, 24, 24, 32)        9248      \n_________________________________________________________________\nmax_pooling2d_6 (MaxPooling2 (None, 12, 12, 32)        0         \n_________________________________________________________________\nconv2d_14 (Conv2D)           (None, 10, 10, 64)        18496     \n_________________________________________________________________\nconv2d_15 (Conv2D)           (None, 8, 8, 64)          36928     \n_________________________________________________________________\nmax_pooling2d_7 (MaxPooling2 (None, 4, 4, 64)          0         \n_________________________________________________________________\nflatten_5 (Flatten)          (None, 1024)              0         \n_________________________________________________________________\ndense_9 (Dense)              (None, 512)               524800    \n_________________________________________________________________\ndense_10 (Dense)             (None, 10)                5130      \n=================================================================\nTotal params: 594,922\nTrainable params: 594,922\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#predictions\npredictions = cnn_model.predict_classes(X_test, verbose=0)\nsubmissions=pd.DataFrame({\"ImageId\": list(range(1,len(predictions)+1)),\n                         \"Label\": predictions})\nsubmissions.to_csv(\"CNN.csv\", index=False, header=True)","execution_count":56,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}